{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p7ZB61JvCSYd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import pipeline\n",
    "import pickle\n",
    "from config import Config\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "81x0frMUDfUR",
    "outputId": "0897822e-bd69-4eda-f21f-3e7a3ec34baa"
   },
   "outputs": [],
   "source": [
    "# device_name = tf.test.gpu_device_name()\n",
    "# if device_name != '/device:GPU:0':\n",
    "#     raise SystemError('GPU device not found')\n",
    "# print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NAKFkKuTCSYn"
   },
   "outputs": [],
   "source": [
    "# Parameters Based on Paper\n",
    "epsilon = 1e-7\n",
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lambda_ = 0.5\n",
    "alpha = 0.0005\n",
    "epochs = 5\n",
    "no_of_secondary_capsules = 10\n",
    "hidden_units = 10\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P-6K7DWeCSYw"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"no_of_conv_kernels\": 256,\n",
    "    \"no_of_primary_capsules\": 32,\n",
    "    \"no_of_secondary_capsules\": 10,\n",
    "    \"primary_capsule_vector\": 8,\n",
    "    \"secondary_capsule_vector\": 16,\n",
    "    \"r\":3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "caLHZNu4CSY1"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = 'D:\\year-end-project/models/final/logs_record/mnist_encoder_logs/model/capsule'\n",
    "\n",
    "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "logdir = 'D:\\year-end-project/models/final/logs_record/mnist_encoder_logs/func/%s' % stamp\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "scalar_logdir = 'D:\\year-end-project/models/final/logs_record/mnist_encoder_logs/scalars/%s' % stamp\n",
    "file_writer = tf.summary.create_file_writer(scalar_logdir + \"/metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ZQe1dcN6CSY6",
    "outputId": "8411c6df-05d0-432f-986c-a12621841ed3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of MNIST images: (70000, 28, 28, 1)\n",
      "Shape of MNIST labels: (70000,)\n",
      "Images Shape: (70000, 28, 28, 1)\n",
      "Labels Shape: (70000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Images: 100%|██████████| 2188/2188 [00:10<00:00, 204.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented Images Shape: (70000, 28, 28, 1)\n",
      "Augmented Labels Shape: (70000,)\n",
      "Combined Images Shape: (140000, 28, 28, 1)\n",
      "Combined Labels Shape: (140000,)\n",
      "Validation Set: Images shape=(3500, 28, 28, 1), Labels shape=(3500,)\n",
      "Training Set:   Images shape=(112000, 28, 28, 1), Labels shape=(112000,)\n",
      "Test Set:       Images shape=(24500, 28, 28, 1), Labels shape=(24500,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mnist = pipeline.CreateDataset(\"mnist\")\n",
    "# mnist.run()\n",
    "# (X_train, y_train), (X_test , y_test)= mnist.get_train_test()\n",
    "with open('mnist/mnist.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "X_train = data[\"X_train\"]\n",
    "y_train = data[\"y_train\"]\n",
    "X_test = data[\"X_test\"]\n",
    "y_test = data[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s2ObVfipCSY_"
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_train = tf.cast(X_train, dtype=tf.float32)\n",
    "X_train = tf.expand_dims(X_train, axis=-1)\n",
    "\n",
    "X_test = X_test / 255.0\n",
    "X_test = tf.cast(X_test, dtype=tf.float32)\n",
    "X_test = tf.expand_dims(X_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W-bhvXFnCSZE"
   },
   "outputs": [],
   "source": [
    "testing_dataset_size = X_test.shape[0]\n",
    "training_dataset_size = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4kP4-BNxCSZI"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "dataset = dataset.shuffle(buffer_size=len(dataset), reshuffle_each_iteration=True)\n",
    "dataset = dataset.batch(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sXB9-g8vCSZL"
   },
   "outputs": [],
   "source": [
    "testing = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "testing = testing.batch(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2rzxmIQCSZQ"
   },
   "outputs": [],
   "source": [
    "class CapsuleNetwork(tf.keras.Model):\n",
    "    def __init__(self, no_of_conv_kernels, no_of_primary_capsules, primary_capsule_vector, no_of_secondary_capsules, secondary_capsule_vector, r):\n",
    "        super(CapsuleNetwork, self).__init__()\n",
    "        self.no_of_conv_kernels = no_of_conv_kernels\n",
    "        self.no_of_primary_capsules = no_of_primary_capsules\n",
    "        self.primary_capsule_vector = primary_capsule_vector\n",
    "        self.no_of_secondary_capsules = no_of_secondary_capsules\n",
    "        self.secondary_capsule_vector = secondary_capsule_vector\n",
    "        self.r = r\n",
    "        \n",
    "        \n",
    "        with tf.name_scope(\"Variables\") as scope:\n",
    "            self.convolution = tf.keras.layers.Conv2D(self.no_of_conv_kernels, [9,9], strides=[1,1], name='ConvolutionLayer', activation='relu')\n",
    "            self.primary_capsule = tf.keras.layers.Conv2D(self.no_of_primary_capsules * self.primary_capsule_vector, [9,9], strides=[2,2], name=\"PrimaryCapsule\")\n",
    "            self.w = tf.Variable(tf.random_normal_initializer()(shape=[1, 1152, self.no_of_secondary_capsules, self.secondary_capsule_vector, self.primary_capsule_vector]), dtype=tf.float32, name=\"PoseEstimation\", trainable=True)\n",
    "            self.dense_1 = tf.keras.layers.Dense(units = 512, activation='relu')\n",
    "            self.dense_2 = tf.keras.layers.Dense(units = 1024, activation='relu')\n",
    "            self.dense_3 = tf.keras.layers.Dense(units = 784, activation='sigmoid', dtype='float32')\n",
    "            self.query_layer = tf.keras.layers.Dense(16)\n",
    "            self.key_layer = tf.keras.layers.Dense(16)\n",
    "            self.value_layer = tf.keras.layers.Dense(16)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "        \n",
    "    def squash(self, s):\n",
    "        with tf.name_scope(\"SquashFunction\") as scope:\n",
    "            s_norm = tf.norm(s, axis=-1, keepdims=True)\n",
    "            return tf.square(s_norm)/(1 + tf.square(s_norm)) * s/(s_norm + epsilon)\n",
    "    \n",
    "    def self_attention(self,input_tensor, hidden_size = 16, activation=tf.nn.relu):\n",
    "        query = self.query_layer(input_tensor)\n",
    "        key = self.key_layer(input_tensor)\n",
    "        value = self.value_layer(input_tensor)\n",
    "\n",
    "        attention_scores = tf.matmul(query, key, transpose_b=True)\n",
    "        attention_scores = tf.divide(attention_scores, tf.sqrt(tf.cast(hidden_size, tf.float32)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(attention_scores)\n",
    "\n",
    "        attended_values = tf.matmul(attention_weights, value)\n",
    "\n",
    "        return attended_values\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        input_x, y = inputs\n",
    "        # input_x.shape: (None, 28, 28, 1)\n",
    "        # y.shape: (None, 10)\n",
    "        \n",
    "        x = self.convolution(input_x) # x.shape: (None, 20, 20, 256)\n",
    "        x = self.primary_capsule(x) # x.shape: (None, 6, 6, 256)\n",
    "        \n",
    "        with tf.name_scope(\"CapsuleFormation\") as scope:\n",
    "            u = tf.reshape(x, (-1, self.no_of_primary_capsules * x.shape[1] * x.shape[2], 8)) # u.shape: (None, 1152, 8)\n",
    "            u = tf.expand_dims(u, axis=-2) # u.shape: (None, 1152, 1, 8)\n",
    "            u = tf.expand_dims(u, axis=-1) # u.shape: (None, 1152, 1, 8, 1)\n",
    "            u_hat = tf.matmul(self.w, u) # u_hat.shape: (None, 1152, 10, 16, 1)\n",
    "            u_hat = tf.squeeze(u_hat, [4]) # u_hat.shape: (None, 1152, 10, 16)\n",
    "\n",
    "        \n",
    "        with tf.name_scope(\"DynamicRouting\") as scope:\n",
    "            b = tf.zeros((input_x.shape[0], 1152, self.no_of_secondary_capsules, 1)) # b.shape: (None, 1152, 10, 1)\n",
    "            for i in range(self.r): # self.r = 3\n",
    "                c = tf.nn.softmax(b, axis=-2) # c.shape: (None, 1152, 10, 1)\n",
    "                s = tf.reduce_sum(tf.multiply(c, u_hat), axis=1, keepdims=True) # s.shape: (None, 1, 10, 16)\n",
    "                v = self.squash(s) # v.shape: (None, 1, 10, 16)\n",
    "                agreement = tf.squeeze(tf.matmul(tf.expand_dims(u_hat, axis=-1), tf.expand_dims(v, axis=-1), transpose_a=True), [4]) # agreement.shape: (None, 1152, 10, 1)\n",
    "                # Before matmul following intermediate shapes are present, they are not assigned to a variable but just for understanding the code.\n",
    "                # u_hat.shape (Intermediate shape) : (None, 1152, 10, 16, 1)\n",
    "                # v.shape (Intermediate shape): (None, 1, 10, 16, 1)\n",
    "                # Since the first parameter of matmul is to be transposed its shape becomes:(None, 1152, 10, 1, 16)\n",
    "                # Now matmul is performed in the last two dimensions, and others are broadcasted\n",
    "                # Before squeezing we have an intermediate shape of (None, 1152, 10, 1, 1)\n",
    "                b += agreement\n",
    "                \n",
    "        with tf.name_scope(\"Masking\") as scope:\n",
    "            y = tf.expand_dims(y, axis=-1) # y.shape: (None, 10, 1)\n",
    "            y = tf.expand_dims(y, axis=1) # y.shape: (None, 1, 10, 1)\n",
    "            mask = tf.cast(y, dtype=tf.float32) # mask.shape: (None, 1, 10, 1)\n",
    "            v_masked = tf.multiply(mask, v) # v_masked.shape: (None, 1, 10, 16)\n",
    "            \n",
    "        with tf.name_scope(\"Reconstruction\") as scope:\n",
    "            v_ = tf.reshape(v_masked, [-1, self.no_of_secondary_capsules * self.secondary_capsule_vector]) # v_.shape: (None, 160)\n",
    "            print()\n",
    "            reconstructed_image = self.self_attention(v_)\n",
    "            reconstructed_image = self.dense_1(reconstructed_image) # reconstructed_image.shape: (None, 512)\n",
    "            reconstructed_image = self.dense_2(reconstructed_image) # reconstructed_image.shape: (None, 1024)\n",
    "            reconstructed_image = self.dense_3(reconstructed_image) # reconstructed_image.shape: (None, 784)\n",
    "        \n",
    "        return v, reconstructed_image\n",
    "\n",
    "    @tf.function\n",
    "    def predict_capsule_output(self, inputs):\n",
    "        x = self.convolution(inputs) # x.shape: (None, 20, 20, 256)\n",
    "        x = self.primary_capsule(x) # x.shape: (None, 6, 6, 256)\n",
    "        \n",
    "        with tf.name_scope(\"CapsuleFormation\") as scope:\n",
    "            u = tf.reshape(x, (-1, self.no_of_primary_capsules * x.shape[1] * x.shape[2], 8)) # u.shape: (None, 1152, 8)\n",
    "            u = tf.expand_dims(u, axis=-2) # u.shape: (None, 1152, 1, 8)\n",
    "            u = tf.expand_dims(u, axis=-1) # u.shape: (None, 1152, 1, 8, 1)\n",
    "            u_hat = tf.matmul(self.w, u) # u_hat.shape: (None, 1152, 10, 16, 1)\n",
    "            u_hat = tf.squeeze(u_hat, [4]) # u_hat.shape: (None, 1152, 10, 16)\n",
    "\n",
    "        \n",
    "        with tf.name_scope(\"DynamicRouting\") as scope:\n",
    "            b = tf.zeros((inputs.shape[0], 1152, self.no_of_secondary_capsules, 1)) # b.shape: (None, 1152, 10, 1)\n",
    "            for i in range(self.r): # self.r = 3\n",
    "                c = tf.nn.softmax(b, axis=-2) # c.shape: (None, 1152, 10, 1)\n",
    "                s = tf.reduce_sum(tf.multiply(c, u_hat), axis=1, keepdims=True) # s.shape: (None, 1, 10, 16)\n",
    "                v = self.squash(s) # v.shape: (None, 1, 10, 16)\n",
    "                agreement = tf.squeeze(tf.matmul(tf.expand_dims(u_hat, axis=-1), tf.expand_dims(v, axis=-1), transpose_a=True), [4]) # agreement.shape: (None, 1152, 10, 1)\n",
    "                # Before matmul following intermediate shapes are present, they are not assigned to a variable but just for understanding the code.\n",
    "                # u_hat.shape (Intermediate shape) : (None, 1152, 10, 16, 1)\n",
    "                # v.shape (Intermediate shape): (None, 1, 10, 16, 1)\n",
    "                # Since the first parameter of matmul is to be transposed its shape becomes:(None, 1152, 10, 1, 16)\n",
    "                # Now matmul is performed in the last two dimensions, and others are broadcasted\n",
    "                # Before squeezing we have an intermediate shape of (None, 1152, 10, 1, 1)\n",
    "                b += agreement\n",
    "        return v\n",
    "\n",
    "    @tf.function\n",
    "    def regenerate_image(self, inputs):\n",
    "        with tf.name_scope(\"Reconstruction\") as scope:\n",
    "            v_ = tf.reshape(inputs, [-1, self.no_of_secondary_capsules * self.secondary_capsule_vector]) # v_.shape: (None, 160)\n",
    "            # reconstructed_image = self.self_attention(v_)\n",
    "            reconstructed_image = self.dense_1(reconstructed_image) # reconstructed_image.shape: (None, 512)\n",
    "            reconstructed_image = self.dense_2(reconstructed_image) # reconstructed_image.shape: (None, 1024)\n",
    "            reconstructed_image = self.dense_3(reconstructed_image) # reconstructed_image.shape: (None, 784)\n",
    "        return reconstructed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HdCBmocACSZT",
    "outputId": "b6fe5ba7-76c2-430e-86a4-32df31c2323b"
   },
   "outputs": [],
   "source": [
    "tf.summary.trace_on(graph=True, profiler=True,profiler_outdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S-lAG5TKCSZZ"
   },
   "outputs": [],
   "source": [
    "model = CapsuleNetwork(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "In9Dx61jCSZd"
   },
   "outputs": [],
   "source": [
    "def safe_norm(v, axis=-1, epsilon=1e-7):\n",
    "    v_ = tf.reduce_sum(tf.square(v), axis = axis, keepdims=True)\n",
    "    return tf.sqrt(v_ + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i96YEEk9CSZg"
   },
   "outputs": [],
   "source": [
    "def loss_function(v, reconstructed_image, y, y_image):\n",
    "    prediction = safe_norm(v)\n",
    "    prediction = tf.reshape(prediction, [-1, no_of_secondary_capsules])\n",
    "    \n",
    "    left_margin = tf.square(tf.maximum(0.0, m_plus - prediction))\n",
    "    right_margin = tf.square(tf.maximum(0.0, prediction - m_minus))\n",
    "    \n",
    "    l = tf.add(y * left_margin, lambda_ * (1.0 - y) * right_margin)\n",
    "    \n",
    "    margin_loss = tf.reduce_mean(tf.reduce_sum(l, axis=-1))\n",
    "    \n",
    "    y_image_flat = tf.reshape(y_image, [-1, 784])\n",
    "    reconstruction_loss = tf.reduce_mean(tf.square(y_image_flat - reconstructed_image))\n",
    "    \n",
    "    loss = tf.add(margin_loss, alpha * reconstruction_loss)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZTlvPfHsCSZk"
   },
   "outputs": [],
   "source": [
    "def train(x,y):\n",
    "    y_one_hot = tf.one_hot(y, depth=10)\n",
    "    with tf.GradientTape() as tape:\n",
    "        v, reconstructed_image = model([x, y_one_hot])\n",
    "        loss = loss_function(v, reconstructed_image, y_one_hot, x)\n",
    "    grad = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grad, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9yviNJHHCSZs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING:tensorflow:Ignoring `profiler_outdir` passed to trace_export(). Please pass it to trace_on() instead.\n",
      "WARNING:tensorflow:Error while stopping profiler: Cannot export profiling results. No profiler is running.\n"
     ]
    }
   ],
   "source": [
    "_ = train(X_train[:32],y_train[:32])\n",
    "with writer.as_default():\n",
    "    tf.summary.trace_export(name=\"my_func_trace\", step=0, profiler_outdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.trace_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "tf2mm1K_CSZv",
    "outputId": "e1a6dc9c-8843-47a8-f84d-cad305beda85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"capsule_network\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"capsule_network\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ ConvolutionLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ PrimaryCapsule (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,308,672</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">803,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,576</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,576</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,576</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ ConvolutionLayer (\u001b[38;5;33mConv2D\u001b[0m)       │ ?                      │        \u001b[38;5;34m20,992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ PrimaryCapsule (\u001b[38;5;33mConv2D\u001b[0m)         │ ?                      │     \u001b[38;5;34m5,308,672\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │         \u001b[38;5;34m8,704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │       \u001b[38;5;34m525,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │       \u001b[38;5;34m803,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │         \u001b[38;5;34m2,576\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │         \u001b[38;5;34m2,576\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │         \u001b[38;5;34m2,576\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,675,008</span> (25.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,675,008\u001b[0m (25.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,675,008</span> (25.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,675,008\u001b[0m (25.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k9MdXHBoCSZy"
   },
   "outputs": [],
   "source": [
    "def predict(model, x):\n",
    "    pred = safe_norm(model.predict_capsule_output(x))\n",
    "    pred = tf.squeeze(pred, [1])\n",
    "    return np.argmax(pred, axis=1)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "603FUUezCSZ0"
   },
   "outputs": [],
   "source": [
    "checkpoint = tf.train.Checkpoint(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821
    },
    "colab_type": "code",
    "id": "rvV7wlg1CSZ3",
    "outputId": "5eab0cff-9236-4d0b-a273-87e599270b89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5228), started 1 day, 6:07:24 ago. (Use '!kill 5228' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2f78b6b86e0e3460\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2f78b6b86e0e3460\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 885
    },
    "colab_type": "code",
    "id": "N9sQf2eCCSZ8",
    "outputId": "e0e7af0a-54e5-4186-f10d-f93452f2a46b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 938/938 [31:39<00:00,  2.02s/it, Loss :0.049937367 Accuracy :0.9875666666666667]\n",
      "Epoch 2/5: 100%|██████████| 938/938 [33:28<00:00,  2.14s/it, Loss :0.018603355 Accuracy :0.9936333333333334]\n",
      "Epoch 3/5: 100%|██████████| 938/938 [55:18<00:00,  3.54s/it, Loss :0.012762793 Accuracy :0.9962]       \n",
      "Epoch 4/5: 100%|██████████| 938/938 [56:45<00:00,  3.63s/it, Loss :0.0093416935 Accuracy :0.9972833333333333]\n",
      "Epoch 5/5: 100%|██████████| 938/938 [51:14<00:00,  3.28s/it, Loss :0.0071801716 Accuracy :0.9982833333333333]\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accuracy = []\n",
    "for i in range(1, epochs+1, 1):\n",
    "\n",
    "    loss = 0\n",
    "    with tqdm(total=len(dataset)) as pbar:\n",
    "        \n",
    "        description = \"Epoch \" + str(i) + \"/\" + str(epochs)\n",
    "        pbar.set_description_str(description)\n",
    "\n",
    "        for X_batch, y_batch in dataset:\n",
    "\n",
    "            loss += train(X_batch,y_batch)\n",
    "            pbar.update(1)\n",
    "\n",
    "        loss /= len(dataset)\n",
    "        losses.append(loss.numpy())\n",
    "        \n",
    "        training_sum = 0\n",
    "\n",
    "        print_statement = \"Loss :\" + str(loss.numpy()) + \" Evaluating Accuracy ...\"\n",
    "        pbar.set_postfix_str(print_statement)\n",
    "\n",
    "        for X_batch, y_batch in dataset:\n",
    "            training_sum += sum(predict(model, X_batch)==y_batch.numpy())\n",
    "        accuracy.append(training_sum/training_dataset_size)\n",
    "\n",
    "        with file_writer.as_default():\n",
    "            tf.summary.scalar('Loss', data=loss.numpy(), step=i)\n",
    "            tf.summary.scalar('Accuracy', data=accuracy[-1], step=i)\n",
    "        \n",
    "        print_statement = \"Loss :\" + str(loss.numpy()) + \" Accuracy :\" + str(accuracy[-1])\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print_statement += ' Checkpoint Saved'\n",
    "            checkpoint.save(checkpoint_path)\n",
    "        \n",
    "        pbar.set_postfix_str(print_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9873\n"
     ]
    }
   ],
   "source": [
    "test_sum = 0\n",
    "for X_batch, y_batch in testing:\n",
    "    test_sum += sum(predict(model, X_batch)==y_batch.numpy())\n",
    "print(test_sum/testing_dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "index_ = 3\n",
    "index = index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict(model, tf.expand_dims(X_test[index_], axis=0)), y_test[index_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model.predict_capsule_output(tf.expand_dims(X_test[index_], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_features = features.numpy()\n",
    "temp_ = temp_features.copy()\n",
    "temp_features[:,:,:,:] = 0\n",
    "temp_features[:,:,index,:] = temp_[:,:,index,:]\n",
    "\n",
    "recon = model.regenerate_image(temp_features)\n",
    "print(recon.shape,temp_features.shape)\n",
    "recon = tf.reshape(recon, (28,28))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(recon, cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(X_test[index_,:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = np.zeros((28,308))\n",
    "for i in range(16): \n",
    "    feature_ = temp_features.copy()\n",
    "    feature_[:,:,index, i] += -0.25\n",
    "    row = np.zeros((28,28))\n",
    "    for j in range(10):\n",
    "        feature_[:,:,index, i] += 0.05\n",
    "        row = np.hstack([row, tf.reshape(model.regenerate_image(tf.convert_to_tensor(feature_)), (28,28)).numpy()])\n",
    "    col = np.vstack([col, row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,20))\n",
    "plt.imshow(col[28:, 28:], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CapsuleNetwork.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
